{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "# import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "import StringIO\n",
    "import sys\n",
    "from math import sqrt\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Data Cleanup and processing stage\n",
    "#### Create some utility methods for data parsing and processing\n",
    "##### loadRecord(line) will parse the record line from the input dataset, does basic sanity checks to verify if there are any problems and returns accordingly\n",
    "##### isANumber(str) will validate if a given string is actually a number. This is to process and check if the data value read for score is a Number\n",
    "##### tokenizer(string) is a simple tokenizer which splits the word based on any non word character and then converts into lowercase\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_regex = r'\\W+'\n",
    "\n",
    "def isANumber(str):\n",
    "    try:\n",
    "        float(str)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def loadRecord(line):\n",
    "    \"\"\"\n",
    "    Parses the records using CSV reader and returns as dict fields\n",
    "    :param line:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    input = StringIO.StringIO(line)\n",
    "    reader = csv.DictReader(input, fieldnames=[\"productId\", \"userId\", \"summary\", \"text\", \"score\"])\n",
    "    rec =reader.next()\n",
    "    # print (\"rec:\", rec, len(rec.get(\"productId\")), len(rec.get(\"userId\")), len(rec.get(\"summary\")), len(rec.get(\"text\")))\n",
    "\n",
    "    if rec is not None:\n",
    "        if (rec.get(\"productId\", \"\") is None \\\n",
    "            or rec.get(\"userId\", \"\") is None \\\n",
    "            or rec.get(\"summary\", \"\") is None \\\n",
    "            or rec.get(\"text\", \"\") is None \\\n",
    "            or rec.get(\"score\", \"\") is None):\n",
    "        # if (len(rec) != 5):\n",
    "            return (rec, 0)\n",
    "        else:\n",
    "            if isANumber(rec.get(\"score\", \"\")):\n",
    "                return (rec, 1)\n",
    "            else:\n",
    "                return (rec, 0)\n",
    "    else:\n",
    "        return (rec, 0)\n",
    "\n",
    "def removeStopWords(tokenList):\n",
    "    stopWords = ['a', 'the', 'of', 'and', 's', 'this', 'is', 'it', 'i', 'to', 'my', 'on', 'you', 'for']\n",
    "    return [w for w in tokenList if not w in stopWords]\n",
    "    \n",
    "def tokenizer(string):\n",
    "    \"\"\" A simple tokenization implementaion\n",
    "        break the string into tokens based on the regex splitter\n",
    "    Args:\n",
    "        string (str): input string\n",
    "    Returns:\n",
    "        list: a list of tokens\n",
    "    \"\"\"\n",
    "    return removeStopWords([x for x in re.split(split_regex, string.lower()) if x != ''])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple', 'string']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"this is a simple-string\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will load the data from the external File. We will also sample the dataset to create a smaller sample size of 1% or 10%\n",
    "#### we will then parse the data. Using the utility functions created above, we will process the dataset and filter out bad records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the dataset and create an RDD excluding the header line\n",
    "input = sc.textFile(\"amazonreviews/movies-reviews.csv\")\n",
    "header = input.take(1)[0]\n",
    "lineslarge = input.filter(lambda line: line != header)\n",
    "\n",
    "# Create a smaller dataset from the large sample for Test and experimentation purposes\n",
    "lines = lineslarge.sample(False,0.01)\n",
    "\n",
    "# parse and load the records, filtering out bad records\n",
    "#   create reviews rdd with label and text\n",
    "parsedRecords = lines.map(lambda line: loadRecord(line.encode('utf-8'))).cache()\n",
    "reviews = parsedRecords.filter(lambda s: s[1] == 1).map(lambda s: s[0]).cache()\n",
    "badrecs = parsedRecords.filter(lambda s: s[1] == 0).map(lambda s: s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Explore input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Records in the dataset:', 78904)\n",
      "('# of good records:', 78904)\n",
      "('# of bad records:', 0)\n"
     ]
    }
   ],
   "source": [
    "totalParsed = parsedRecords.count()\n",
    "goodRecs = reviews.count()\n",
    "badRecs = totalParsed - goodRecs\n",
    "print (\"Total Records in the dataset:\" ,totalParsed)\n",
    "print (\"# of good records:\" ,goodRecs)\n",
    "print (\"# of bad records:\" ,badRecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Training and Test dataset. Transform data to create input features using the Bag-of-Words TF-IDF model\n",
    "\n",
    "#### We will now split the dataset into a tTraining set and Test set. We will create training RDD and TestRDD which will contain the labeled data points and the review texts (which comes from the summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the dataset to training and test data\n",
    "trainingRDD, testRDD = reviews.randomSplit([8, 2], seed=0L)\n",
    "\n",
    "# Create a trainingRDD with the labels, and the review text\n",
    "labelsTrainingRDD = trainingRDD.map(lambda fields:fields.get(\"score\")).map(lambda score: (1 if float(score) >= 3 else 0 ))\n",
    "reviewTextTokensTrainingRDD = trainingRDD.map(lambda fields:fields.get(\"summary\")).map(lambda text: tokenizer(text))\n",
    "\n",
    "# Create a testRDD with the labels, and the review text\n",
    "labelsTestRDD = testRDD.map(lambda fields:fields.get(\"score\")).map(lambda score: (1 if float(score) >= 3 else 0 ))\n",
    "reviewTextTokensTestRDD = testRDD.map(lambda fields:fields.get(\"summary\")).map(lambda text: tokenizer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.a. Explore the parsed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['completely', 'misses', 'point'],\n",
       " ['classic', 'with', 'some', 'cool', 'extras'],\n",
       " ['enjoyable', 'journey'],\n",
       " ['great', 'movie'],\n",
       " ['last', 'samurai']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at a couple of reviews\n",
    "reviewTextTokensTrainingRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20124\n"
     ]
    }
   ],
   "source": [
    "# how many unique tokens\n",
    "tokenCounts = reviewTextTokensTrainingRDD.flatMap(lambda text: text).map(lambda token: (token,1)).reduceByKey(lambda x, y: x + y)\n",
    "print tokenCounts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 7349),\n",
       " ('great', 5262),\n",
       " ('it', 3980),\n",
       " ('to', 3419),\n",
       " ('good', 3312),\n",
       " ('for', 3146),\n",
       " ('i', 3093),\n",
       " ('not', 2835),\n",
       " ('best', 2766),\n",
       " ('but', 2582),\n",
       " ('film', 2550),\n",
       " ('in', 2537),\n",
       " ('one', 2169),\n",
       " ('you', 2105),\n",
       " ('dvd', 2064),\n",
       " ('classic', 1606),\n",
       " ('t', 1563),\n",
       " ('on', 1503),\n",
       " ('love', 1471),\n",
       " ('with', 1428),\n",
       " ('all', 1352),\n",
       " ('my', 1334),\n",
       " ('very', 1294),\n",
       " ('as', 1259),\n",
       " ('ever', 1249),\n",
       " ('an', 1243),\n",
       " ('what', 1163),\n",
       " ('excellent', 1111),\n",
       " ('time', 1099),\n",
       " ('fun', 1090)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the top 10 tokens\n",
    "tokenCounts.sortBy(lambda x: -x[1]).take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets look at the words most appearing in positive sentiments and words most appearing in negative sentiments\n",
    "positiveTokens = labelsTrainingRDD.zip(reviewTextTokensTrainingRDD).flatMapValues(lambda x: x).filter(lambda x: x[0] ==1)\n",
    "negativeTokens = labelsTrainingRDD.zip(reviewTextTokensTrainingRDD).flatMapValues(lambda x: x).filter(lambda x: x[0] ==0)\n",
    "positiveTokenCounts = positiveTokens.map(lambda l: (l[1],1)).reduceByKey(lambda x, y: x + y)\n",
    "negativeTokenCounts = negativeTokens.map(lambda l: (l[1],1)).reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tokens: [('movie', 6466), ('great', 5060), ('good', 3017), ('best', 2708), ('film', 2300), ('but', 2245), ('in', 2234), ('not', 1995), ('one', 1952), ('dvd', 1757)]\n",
      "Negative tokens: [('movie', 883), ('not', 840), ('t', 439), ('bad', 402), ('but', 337), ('dvd', 307), ('in', 303), ('good', 295), ('what', 278), ('worst', 268)]\n"
     ]
    }
   ],
   "source": [
    "print \"Top Positive tokens:\", positiveTokenCounts.sortBy(lambda x: -x[1]).take(10)\n",
    "print \"Top Negative tokens:\", negativeTokenCounts.sortBy(lambda x: -x[1]).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create the input features which is a weighted bag-of-words model using TF-IDF: \n",
    "#### TF is weighted at the document level (or to the individual input text) such that it assigns greater weights to tokens that appear more frequently within the document. IDF is weighted to at the corpus level and assigns more weights to tokens that appear less frequently. IDF kind of normalizes the commonly occuring words, so the stop words get lesser weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create TF-IDF model features on the training review text data\n",
    "tfTrain = HashingTF().transform(reviewTextTokensTrainingRDD)\n",
    "idfTrain = IDF().fit(tfTrain)\n",
    "tfidfTrain = idfTrain.transform(tfTrain)\n",
    "\n",
    "# Combine the labels with the TF-IDF feature vectors\n",
    "training = labelsTrainingRDD.zip(tfidfTrain).map(lambda x: LabeledPoint(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train the Naive Bayes classifier, using the TF-IDF bag of words as the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now train a naive bayes classifier, using the TF-IDF feature set\n",
    "model = NaiveBayes.train(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Transform the test dataset to create the TF-IDF features, using the same model that was trained earlier, and make the predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create TF-IDF model features on the test review text data\n",
    "tfTest = HashingTF().transform(reviewTextTokensTestRDD)\n",
    "# idfTest = IDF().fit(tfTest)\n",
    "tfidfTest = idfTrain.transform(tfTest)\n",
    "\n",
    "#Lets predict out accuracy\n",
    "# predictedRDD =  labelsTrainingRDD.zip(model.predict(tfidfTrain)).map(lambda x: {\"actual\": x[0], \"predicted\": x[1]})\n",
    "\n",
    "predictedRDD =  labelsTestRDD.zip(model.predict(tfidfTest)).cache()\n",
    "sampleCount =  predictedRDD.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.8752366527830368, ', Predicted on the test set of count:', 15846)\n"
     ]
    }
   ],
   "source": [
    "accuracy = 1.0 * predictedRDD.filter(lambda x: x[0] == x[1]).count() / sampleCount\n",
    "print (\"Accuracy:\", accuracy, \", Predicted on the test set of count:\", sampleCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Explore the inaccuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incorrectPredictions = predictedRDD.zip(testRDD.map(lambda fields:fields.get(\"summary\"))).filter(lambda x: x[0][0] != x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total incorrect predictions: 1977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Actual sentiment': 1,\n",
       "  'Predicted sentiment': 0.0,\n",
       "  'Review text': 'Hilariously Eurocentric'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Rent it (unless it\\'s cheaper to buy it \"previously viewed\")'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Hannibal the Cannibal meets Miami Vice'},\n",
       " {'Actual sentiment': 1,\n",
       "  'Predicted sentiment': 0.0,\n",
       "  'Review text': 'The Cardinal'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Not a very good film in 1963, and now very dated.'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'typical Oliver Stone'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': \"Even The Very Hot Elisha Can't Save This Lukewarm Flick\"},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Soul Plane (R-Rated)'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Over the top and over again'},\n",
       " {'Actual sentiment': 0, 'Predicted sentiment': 1.0, 'Review text': 'Eh...'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Great movie...dissapointing dvd'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Blu Ray missing bang'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'I was a little disappointed in the presentation'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Beneath The 12-Mile Reef.'},\n",
       " {'Actual sentiment': 1,\n",
       "  'Predicted sentiment': 0.0,\n",
       "  'Review text': 'Highwaymen'},\n",
       " {'Actual sentiment': 1, 'Predicted sentiment': 0.0, 'Review text': 'Oof!'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Must be seen'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Another good way to waste your time.'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'best of kitaro'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'It may be always sunny but NOT always funny!!'},\n",
       " {'Actual sentiment': 1,\n",
       "  'Predicted sentiment': 0.0,\n",
       "  'Review text': 'Hoodwinded DVD'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Only for little girls to watch...'},\n",
       " {'Actual sentiment': 1,\n",
       "  'Predicted sentiment': 0.0,\n",
       "  'Review text': 'Bad roadside assistance...'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Epic fail'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'What Was george Cloonet Thinking?'},\n",
       " {'Actual sentiment': 0, 'Predicted sentiment': 1.0, 'Review text': \"D'Oh!\"},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'An onion by any other label...'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Ultimate Gift'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Yea, but...'},\n",
       " {'Actual sentiment': 0,\n",
       "  'Predicted sentiment': 1.0,\n",
       "  'Review text': 'Probably the weakest of the trilogy'}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Total incorrect predictions:\",incorrectPredictions.count()\n",
    "incorrectPredictions.map(lambda x: {\"Actual sentiment\":x[0][0], \"Predicted sentiment\":x[0][1], \"Review text\":x[1]}).take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
